
# Logs------------------------------------------------------------------------------------

logSearchInfo = false
logMoves = false
logGamesEvery = 10
logToStdout = true

# Data writing-----------------------------------------------------------------------------------

maxDataQueueSize = 2000
maxRowsPerTrainFile = 10000
firstFileRandMinProp = 0.15

# Fancy game selfplay settings--------------------------------------------------------------------

# These take dominance - if a game is forked for any of these reasons, that will be the next game played.
# For forked games, randomization of rules and "initGamesWithPolicy" is disabled, komi is made fair with prob "forkCompensateKomiProb".
earlyForkGameProb = 0.04  # Fork to try alternative opening variety with this probability
earlyForkGameExpectedMoveProp = 0.025  # Fork roughly within the first (boardArea * this) many moves
forkGameProb = 0.01 # Fork to try alternative crazy move anywhere in game with this probability if not early forking
forkGameMinChoices = 3   # Choose from the best of at least this many random choices
earlyForkGameMaxChoices = 12  # Choose from the best of at most this many random choices
forkGameMaxChoices = 36  # Choose from the best of at most this many random choices

# Otherwise, play some proportion of games starting from SGF positions, with randomized rules (ignoring the sgf rules)
# On SGF positions, high temperature policy init is allowed
# startPosesProb = 0.0  # Play this proportion of games starting from SGF positions
# startPosesFromSgfDir = DIRECTORYPATH  # Load SGFs from this dir
# startPosesLoadProb = 1.0  # Only load each position from each SGF with this chance (save memory)
# startPosesTurnWeightLambda = 0  # 0 = equal weight  0.01 = decrease probability by 1% per turn  -0.01 = increase probability by 1% per turn.
# startPosesPolicyInitAreaProp = 0.0  # Same as policyInitAreaProp but for SGF positions

# Otherwise, play some proportion of games starting from hint positions (generated using "dataminesgfs" command), with randomized rules.
# On hint positions, "initGamesWithPolicy" does not apply.
# hintPosesProb = 0.0
# hintPosesDir = DIRECTORYPATH

# Otherwise we are playing a "normal" game, potentially with handicap stones, depending on "handicapProb", and
# potentially with komi randomization, depending on things like "komiStdev", and potentially with different
# board sizes, etc.

# Most of the remaining parameters here below apply regardless of the initialization, although a few of them
# vary depending on handicap vs normal game, and some are explicitly disabled (e.g. initGamesWithPolicy on hint positions).

initGamesWithPolicy = true  # Play the first few moves of a game high-temperaturely from policy
policyInitAreaProp = 0.04 # The avg number of moves to play
compensateAfterPolicyInitProb = 0.2 # Additionally make komi fair this often after the high-temperature moves.
sidePositionProb = 0.020  # With this probability, train on refuting bad alternative moves.

cheapSearchProb = 0.75  # Do cheap searches with this probaiblity
cheapSearchVisits = 100  # Number of visits for cheap search
cheapSearchTargetWeight = 0.0  # Training weight for cheap search

reduceVisits = true  # Reduce visits when one side is winning
reduceVisitsThreshold = 0.9  # How winning a side needs to be (winrate)
reduceVisitsThresholdLookback = 3  # How many consecutive turns needed to be that winning
reducedVisitsMin = 100  # Minimum number of visits (never reduce below this)
reducedVisitsWeight = 0.1  # Minimum training weight

handicapAsymmetricPlayoutProb = 0.5  # In handicap games, play with unbalanced players with this probablity
normalAsymmetricPlayoutProb = 0.01  # In regular games, play with unbalanced players with this probability
maxAsymmetricRatio = 8.0 # Max ratio to unbalance visits between players
minAsymmetricCompensateKomiProb = 0.4 # Compensate komi with at least this probability for unbalanced players

policySurpriseDataWeight = 0.5  # This proportion of training weight should be concentrated on surprising moves
valueSurpriseDataWeight = 0.1   # This proportion of training weight should be concentrated on surprising position results

estimateLeadProb = 0.05 # Train lead, rather than just scoremean. Consumes a decent number of extra visits, can be quite slow using low visits to set too high.
switchNetsMidGame = true  # When a new neural net is loaded, switch to it immediately instead of waiting for new game

# Match-----------------------------------------------------------------------------------

numGameThreads = 16
maxMovesPerGame = 1600

# Rules------------------------------------------------------------------------------------

dots = true
multiStoneSuicideLegals = false,true

#bSizesXY=20-20,36-36,39-32,24-24,30-30
#bSizeRelProbs=10,2,1

#bSizesXY=20-20,16-16,10-10,24-24
#bSizeRelProbs=3,2,2,1

#bSizesXY=8-8,10-10,9-9,8-10,10-9,12-12
#bSizeRelProbs=4,4,2,1,1,1

bSizesXY=10-10,12-12,14-14
bSizeRelProbs=1,2,1

startPoses=SINGLE,CROSS,CROSS,CROSS,CROSS_2,CROSS_4,CROSS_4
startPosesAreRandom=false
dotsCaptureEmptyBases=false,false,false,false,false,false,false,true
#dotsFreeCapturedDots=true,true,true,false

# komiAuto = True  # Automatically adjust komi to what the neural nets think are fair based on the empty board, but still apply komiStdev.
                   # Not completed and not tested for Dots game, don't use it
# The following values are probably good for all start poses except SINGLE (for Dots game).
# SINGLE is a special start pos: with allowDraw=true the acceptable komi range is [-1.0; 0.0],
# while with allowDraw=false the acceptable range is only the single value 0.5:
# the red player should capture something to avoid losing.
#
# Other start poses have acceptable ranges that are symmetric relative to zero:
#   CROSS: [-2.0; 2.0]
#   CROSS_4: [-8.0; 8.0]
# However, the engine properly contains the range and it disallows unacceptable komi values.
# So, feel free to set up, for instance, `komiMean` to 0.0 and `komiStdev` to 2.0 to experiment with self-training.
# Also, you might be interested in playing with `komiAllowIntegerProb`, which is used to get rid of draws completely (komiAllowIntegerProb = 0 disables draws).
komiMean = 0.0 # Specify explicit komi
komiStdev = 1.0  # Standard deviation of random variation to komi.
# komiAllowIntegerProb = 0.0

handicapProb = 0.0 # Probability of handicap game.
                   # Not completed and not tested for Dots game, don't use
handicapCompensateKomiProb = 0.00 # In handicap games, adjust komi to fair with this probability based on the handicap placement
forkCompensateKomiProb = 0.00     # For forks, adjust komi to fair with this probability based on the forked position
sgfCompensateKomiProb = 0.00      # For sgfs, adjust komi to fair with this probability based on the specific starting position

drawRandRadius = 0.5

# Search limits-----------------------------------------------------------------------------------

maxVisits = 600
numSearchThreads = 16

# GPU Settings-------------------------------------------------------------------------------

nnMaxBatchSize = 128
nnCacheSizePowerOfTwo = 21
nnMutexPoolSizePowerOfTwo = 15
numNNServerThreadsPerModel = 1
nnRandomize = true

# CUDA GPU settings--------------------------------------
# cudaDeviceToUse = 0 #use device 0 for all server threads (numNNServerThreadsPerModel) unless otherwise specified per-model or per-thread-per-model
# cudaDeviceToUseModel0 = 3 #use device 3 for model 0 for all threads unless otherwise specified per-thread for this model
# cudaDeviceToUseModel1 = 2 #use device 2 for model 1 for all threads unless otherwise specified per-thread for this model
# cudaDeviceToUseModel0Thread0 = 3 #use device 3 for model 0, server thread 0
# cudaDeviceToUseModel0Thread1 = 2 #use device 2 for model 0, server thread 1

cudaUseFP16 = auto
cudaUseNHWC = auto

# Root move selection and biases------------------------------------------------------------------------------

chosenMoveTemperatureEarly = 0.75
chosenMoveTemperatureHalflife = 19
chosenMoveTemperature = 0.15
chosenMoveSubtract = 0
chosenMovePrune = 1

rootNoiseEnabled = true
rootDirichletNoiseTotalConcentration = 10.83
rootDirichletNoiseWeight = 0.25

rootDesiredPerChildVisitsCoeff = 2
rootNumSymmetriesToSample = 4

useLcbForSelection = true
lcbStdevs = 5.0
minVisitPropForLCB = 0.15

# Internal params------------------------------------------------------------------------------

winLossUtilityFactor = 1.0
staticScoreUtilityFactor = 0.00
dynamicScoreUtilityFactor = 0.40
dynamicScoreCenterZeroWeight = 0.25
dynamicScoreCenterScale = 0.50
noResultUtilityForWhite = 0.0
drawEquivalentWinsForWhite = 0.5

rootEndingBonusPoints = 0.5
rootPruneUselessMoves = true

rootPolicyTemperatureEarly = 1.25
rootPolicyTemperature = 1.1

cpuctExploration = 1.1
cpuctExplorationLog = 0.0
fpuReductionMax = 0.2
rootFpuReductionMax = 0.0

numVirtualLossesPerThread = 1

# These parameters didn't exist historically during early KataGo runs
valueWeightExponent = 0.5
subtreeValueBiasFactor = 0.30
subtreeValueBiasWeightExponent = 0.8
useNonBuggyLcb = true
useGraphSearch = true
fpuParentWeightByVisitedPolicy = true
fpuParentWeightByVisitedPolicyPow = 2.0
